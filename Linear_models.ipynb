{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e92b16e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Linear Regression\n",
    "will test OLS and SGD using random data sets, same seed for consetenticy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6d2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe5b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters / assumptions\n",
    "n_samples = 2000\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)\n",
    "noise_std = 3.0 # Standard deviation of the Gaussian noise\n",
    "\n",
    "# Generate 1D feature X in range [-10, 10]\n",
    "X = rng.uniform(-10.0, 10.0, size=(n_samples, 1))\n",
    "\n",
    "# True linear model parameters\n",
    "true_w = 3.0    # slope\n",
    "true_b = 5.0    # intercept\n",
    "\n",
    "# Targets with Gaussian noise, such that y = Mx + b + epsilon(noise)\n",
    "noise = rng.normal(0.0, noise_std, size=(n_samples, 1))\n",
    "y = true_w * X + true_b + noise\n",
    "y = y.ravel()\n",
    "\n",
    "# Quick visualization of the generated data\n",
    "print(\"X shape:\", X.shape, \"y shape:\", y.shape)\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.scatter(X, y, s=8, alpha=0.6)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Generated data with noise (n={n_samples})\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f201782",
   "metadata": {},
   "source": [
    "Fit the line in OLS & SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f4caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# two approaches to linear regression: OLS and SGD\n",
    "\n",
    "# 1. OLS using LinearRegression\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X, y)\n",
    "\n",
    "# 2. SGD using SGDRegressor\n",
    "\n",
    "# SGD is sensitive to the scale of data, so we scale X and y \n",
    "scaler_y = StandardScaler()\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Initialize and train the SGD model\n",
    "# We set max_iter and tolerance for convergence\n",
    "sgd_model = SGDRegressor(\n",
    "    loss='squared_error',\n",
    "    alpha=0.0001,\n",
    "    max_iter=1000,\n",
    "    tol=1e-3,\n",
    "    random_state=42\n",
    ")\n",
    "# Fit the model on scaled data\n",
    "sgd_model.fit(X_scaled, y_scaled)\n",
    "\n",
    "# The SGD coefficients are for the *scaled* data. We need to convert them back\n",
    "# to the original scale for comparison.\n",
    "sgd_w_scaled = sgd_model.coef_[0]\n",
    "sgd_b_scaled = sgd_model.intercept_[0]\n",
    "\n",
    "# Unscale the weights (w_orig = w_scaled * (std_y / std_x))\n",
    "sgd_w_orig = sgd_w_scaled * (scaler_y.scale_ / scaler_X.scale_)\n",
    "# Unscale the intercept (b_orig = b_scaled * std_y + mean_y - w_orig * mean_x)\n",
    "sgd_b_orig = sgd_b_scaled * scaler_y.scale_ + scaler_y.mean_ - sgd_w_orig * scaler_X.mean_\n",
    "\n",
    "# --- Results ---\n",
    "# Prepare predictions for plotting and metrics (using unscaled models for consistency)\n",
    "y_pred_ols = ols_model.predict(X)\n",
    "\n",
    "# For SGD, use the unscaled parameters to calculate predictions on unscaled X\n",
    "y_pred_sgd = sgd_w_orig * X.ravel() + sgd_b_orig\n",
    "\n",
    "print(\"## ðŸ“Š Model Comparison\")\n",
    "print(f\"| Metric | True Value | OLS (LinearRegression) | SGDRegressor (Unscaled) |\")\n",
    "print(f\"| :--- | :--- | :--- | :--- |\")\n",
    "print(f\"| **Slope (w)** | {true_w:.4f} | {ols_model.coef_[0]:.4f} | {sgd_w_orig[0]:.4f} |\")\n",
    "print(f\"| **Intercept (b)** | {true_b:.4f} | {ols_model.intercept_:.4f} | {sgd_b_orig[0]:.4f} |\")\n",
    "print(f\"| **RMSE** | N/A | {mean_squared_error(y, y_pred_ols, squared=False):.4f} | {mean_squared_error(y, y_pred_sgd, squared=False):.4f} |\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(X, y, s=8, alpha=0.5, label='Generated Data')\n",
    "plt.plot(X, true_w * X + true_b, color='black', linestyle='--', linewidth=2, label='True Line')\n",
    "plt.plot(X, y_pred_ols, color='red', linestyle='-', linewidth=2, label=f'OLS Fit (w={ols_model.coef_[0]:.2f})')\n",
    "plt.plot(X, y_pred_sgd, color='green', linestyle='-', linewidth=1.5, alpha=0.7, label=f'SGD Fit (w={sgd_w_orig[0]:.2f})')\n",
    "\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Comparison of OLS and SGD Linear Fits\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
